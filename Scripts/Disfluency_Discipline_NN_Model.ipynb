{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a014759",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463bb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bc6d5",
   "metadata": {},
   "source": [
    "# Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b469a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Interactivity_by_bu_pause</th>\n",
       "      <th>Level</th>\n",
       "      <th>Class_size</th>\n",
       "      <th>Gender</th>\n",
       "      <th>between_clause</th>\n",
       "      <th>between_phrase</th>\n",
       "      <th>between_utterance</th>\n",
       "      <th>disfluency</th>\n",
       "      <th>event_related</th>\n",
       "      <th>within_phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ahlct001</th>\n",
       "      <td>ah</td>\n",
       "      <td>medium</td>\n",
       "      <td>PG</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>66.628809</td>\n",
       "      <td>52.432330</td>\n",
       "      <td>0.094643</td>\n",
       "      <td>22.146508</td>\n",
       "      <td>11.262540</td>\n",
       "      <td>17.508991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahlct002</th>\n",
       "      <td>ah</td>\n",
       "      <td>low</td>\n",
       "      <td>UG</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>42.553191</td>\n",
       "      <td>35.895209</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>55.724417</td>\n",
       "      <td>4.921117</td>\n",
       "      <td>12.737010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahlct003</th>\n",
       "      <td>ah</td>\n",
       "      <td>high</td>\n",
       "      <td>UG</td>\n",
       "      <td>small</td>\n",
       "      <td>male</td>\n",
       "      <td>73.476980</td>\n",
       "      <td>58.595567</td>\n",
       "      <td>2.945280</td>\n",
       "      <td>30.382886</td>\n",
       "      <td>5.270501</td>\n",
       "      <td>28.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahlct004</th>\n",
       "      <td>ah</td>\n",
       "      <td>low</td>\n",
       "      <td>UG</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>96.973347</td>\n",
       "      <td>95.919289</td>\n",
       "      <td>0.150580</td>\n",
       "      <td>9.486523</td>\n",
       "      <td>10.239422</td>\n",
       "      <td>35.536817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahlct005</th>\n",
       "      <td>ah</td>\n",
       "      <td>low</td>\n",
       "      <td>UG</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>70.723442</td>\n",
       "      <td>99.602181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.931929</td>\n",
       "      <td>6.482982</td>\n",
       "      <td>37.277147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sslct036</th>\n",
       "      <td>ss</td>\n",
       "      <td>medium</td>\n",
       "      <td>UG</td>\n",
       "      <td>small</td>\n",
       "      <td>male</td>\n",
       "      <td>55.114763</td>\n",
       "      <td>33.295551</td>\n",
       "      <td>0.141683</td>\n",
       "      <td>55.398130</td>\n",
       "      <td>23.377727</td>\n",
       "      <td>22.810995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sslct037</th>\n",
       "      <td>ss</td>\n",
       "      <td>high</td>\n",
       "      <td>UG</td>\n",
       "      <td>small</td>\n",
       "      <td>female</td>\n",
       "      <td>55.668016</td>\n",
       "      <td>21.761134</td>\n",
       "      <td>1.391700</td>\n",
       "      <td>21.002024</td>\n",
       "      <td>0.759109</td>\n",
       "      <td>14.929150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sslct038</th>\n",
       "      <td>ss</td>\n",
       "      <td>high</td>\n",
       "      <td>UG</td>\n",
       "      <td>large</td>\n",
       "      <td>female</td>\n",
       "      <td>54.283405</td>\n",
       "      <td>44.046336</td>\n",
       "      <td>2.963362</td>\n",
       "      <td>47.683190</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>24.919181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sslct039</th>\n",
       "      <td>ss</td>\n",
       "      <td>high</td>\n",
       "      <td>PG</td>\n",
       "      <td>small</td>\n",
       "      <td>female</td>\n",
       "      <td>56.948576</td>\n",
       "      <td>26.066015</td>\n",
       "      <td>4.674883</td>\n",
       "      <td>42.782264</td>\n",
       "      <td>7.649809</td>\n",
       "      <td>15.441281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sslct040</th>\n",
       "      <td>ss</td>\n",
       "      <td>medium</td>\n",
       "      <td>PG</td>\n",
       "      <td>small</td>\n",
       "      <td>female</td>\n",
       "      <td>57.800824</td>\n",
       "      <td>45.600122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.351228</td>\n",
       "      <td>10.065579</td>\n",
       "      <td>16.623456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Discipline Interactivity_by_bu_pause Level Class_size  Gender  \\\n",
       "Filename                                                                 \n",
       "ahlct001         ah                    medium    PG     medium    male   \n",
       "ahlct002         ah                       low    UG     medium    male   \n",
       "ahlct003         ah                      high    UG      small    male   \n",
       "ahlct004         ah                       low    UG     medium    male   \n",
       "ahlct005         ah                       low    UG     medium    male   \n",
       "...             ...                       ...   ...        ...     ...   \n",
       "sslct036         ss                    medium    UG      small    male   \n",
       "sslct037         ss                      high    UG      small  female   \n",
       "sslct038         ss                      high    UG      large  female   \n",
       "sslct039         ss                      high    PG      small  female   \n",
       "sslct040         ss                    medium    PG      small  female   \n",
       "\n",
       "          between_clause  between_phrase  between_utterance  disfluency  \\\n",
       "Filename                                                                  \n",
       "ahlct001       66.628809       52.432330           0.094643   22.146508   \n",
       "ahlct002       42.553191       35.895209           0.144739   55.724417   \n",
       "ahlct003       73.476980       58.595567           2.945280   30.382886   \n",
       "ahlct004       96.973347       95.919289           0.150580    9.486523   \n",
       "ahlct005       70.723442       99.602181           0.000000   25.931929   \n",
       "...                  ...             ...                ...         ...   \n",
       "sslct036       55.114763       33.295551           0.141683   55.398130   \n",
       "sslct037       55.668016       21.761134           1.391700   21.002024   \n",
       "sslct038       54.283405       44.046336           2.963362   47.683190   \n",
       "sslct039       56.948576       26.066015           4.674883   42.782264   \n",
       "sslct040       57.800824       45.600122           0.000000   21.351228   \n",
       "\n",
       "          event_related  within_phrase  \n",
       "Filename                                \n",
       "ahlct001      11.262540      17.508991  \n",
       "ahlct002       4.921117      12.737010  \n",
       "ahlct003       5.270501      28.987754  \n",
       "ahlct004      10.239422      35.536817  \n",
       "ahlct005       6.482982      37.277147  \n",
       "...                 ...            ...  \n",
       "sslct036      23.377727      22.810995  \n",
       "sslct037       0.759109      14.929150  \n",
       "sslct038      23.437500      24.919181  \n",
       "sslct039       7.649809      15.441281  \n",
       "sslct040      10.065579      16.623456  \n",
       "\n",
       "[158 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pause_freq_2_wide.csv', index_col='Filename')\n",
    "df = df.drop(index='lslct035')\n",
    "df = df.drop(index='lslct036')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58147a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Discipline'] = df['Discipline'].replace({'ah': 0, \n",
    "                          'ls': 1,\n",
    "                          'ps': 2,\n",
    "                          'ss': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ea7751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Discipline', 'Interactivity_by_bu_pause', 'Level', 'Class_size',\n",
       "       'Gender', 'between_clause', 'between_phrase', 'between_utterance',\n",
       "       'disfluency', 'event_related', 'within_phrase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1f86d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 22:54:46.050712: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X = tf.cast(df.iloc[:, 9], dtype=tf.float32)/120\n",
    "Y = tf.cast(df['Discipline'], dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0b97a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([158]), TensorShape([158]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69684d",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "## 1. relu + softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d8fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,))\n",
    "x = layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "for _ in range(4):\n",
    "    x = layers.Dense(4, activation=tf.nn.relu)(x)\n",
    "outputs = layers.Dense(4, activation=tf.nn.softmax)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54d6767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 8         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472251b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 1.3362 - accuracy: 0.3175 - val_loss: 1.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3361 - accuracy: 0.3175 - val_loss: 1.6347 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3360 - accuracy: 0.3175 - val_loss: 1.6348 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3361 - accuracy: 0.3175 - val_loss: 1.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3360 - accuracy: 0.3175 - val_loss: 1.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3360 - accuracy: 0.3175 - val_loss: 1.6351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3360 - accuracy: 0.3175 - val_loss: 1.6352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3360 - accuracy: 0.3175 - val_loss: 1.6353 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3359 - accuracy: 0.3175 - val_loss: 1.6353 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3359 - accuracy: 0.3175 - val_loss: 1.6354 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3359 - accuracy: 0.3175 - val_loss: 1.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3359 - accuracy: 0.3175 - val_loss: 1.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6358 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.26 - 0s 24ms/step - loss: 1.3359 - accuracy: 0.3175 - val_loss: 1.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6360 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6363 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6363 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3358 - accuracy: 0.3175 - val_loss: 1.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6366 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3357 - accuracy: 0.3175 - val_loss: 1.6369 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6369 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6374 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6374 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6376 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6379 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6379 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6380 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3966 - accuracy: 0.2532\n",
      "Test loss: 1.3966166973114014\n",
      "Test accuracy: 0.2531645596027374\n"
     ]
    }
   ],
   "source": [
    "# mini batch\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(X, Y, batch_size=64, epochs=50, validation_split=0.2)\n",
    "train_scores = model.evaluate(X, Y, verbose=1)\n",
    "print(\"Test loss:\", train_scores[0])\n",
    "print(\"Test accuracy:\", train_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095f0efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 41ms/step - loss: 1.3355 - accuracy: 0.3175 - val_loss: 1.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3356 - accuracy: 0.3175 - val_loss: 1.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3354 - accuracy: 0.3175 - val_loss: 1.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6391 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.3175 - val_loss: 1.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6393 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3352 - accuracy: 0.3175 - val_loss: 1.6393 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.3175 - val_loss: 1.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3353 - accuracy: 0.3175 - val_loss: 1.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3352 - accuracy: 0.3175 - val_loss: 1.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3352 - accuracy: 0.3175 - val_loss: 1.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6399 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6400 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6400 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6401 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3351 - accuracy: 0.3175 - val_loss: 1.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6403 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6403 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6407 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6407 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6409 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6409 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3350 - accuracy: 0.3175 - val_loss: 1.6412 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3349 - accuracy: 0.3175 - val_loss: 1.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3347 - accuracy: 0.3175 - val_loss: 1.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - accuracy: 0.3175 - val_loss: 1.6417 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3968 - accuracy: 0.2532\n",
      "Test loss: 1.3968181610107422\n",
      "Test accuracy: 0.2531645596027374\n"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, validation_split=0.2)\n",
    "train_scores = model.evaluate(X, Y, verbose=1)\n",
    "print(\"Test loss:\", train_scores[0])\n",
    "print(\"Test accuracy:\", train_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca416c9b",
   "metadata": {},
   "source": [
    "## 2. tanh + softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a62c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = keras.Input(shape=(1,))\n",
    "x2 = layers.Dense(4, activation=tf.nn.relu)(inputs2)\n",
    "for _ in range(20):\n",
    "    x2 = layers.Dense(4, activation=tf.nn.tanh)(x2)\n",
    "outputs2 = layers.Dense(4, activation=tf.nn.softmax)(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd37f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 8         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 428\n",
      "Trainable params: 428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Model(inputs=inputs2, outputs=outputs2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5085b436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 1.3122 - accuracy: 0.3889 - val_loss: 1.6673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2851 - accuracy: 0.4365 - val_loss: 1.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2983 - accuracy: 0.4048 - val_loss: 1.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2778 - accuracy: 0.4683 - val_loss: 1.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2874 - accuracy: 0.4365 - val_loss: 1.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2701 - accuracy: 0.4921 - val_loss: 1.6706 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2696 - accuracy: 0.4841 - val_loss: 1.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2690 - accuracy: 0.4921 - val_loss: 1.6704 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2704 - accuracy: 0.5000 - val_loss: 1.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2683 - accuracy: 0.4841 - val_loss: 1.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2831 - accuracy: 0.4365 - val_loss: 1.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2884 - accuracy: 0.4206 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2683 - accuracy: 0.4841 - val_loss: 1.6694 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2685 - accuracy: 0.4921 - val_loss: 1.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2702 - accuracy: 0.4683 - val_loss: 1.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2854 - accuracy: 0.4206 - val_loss: 1.6729 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2683 - accuracy: 0.4841 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2682 - accuracy: 0.4841 - val_loss: 1.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2672 - accuracy: 0.4762 - val_loss: 1.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2657 - accuracy: 0.4762 - val_loss: 1.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2772 - accuracy: 0.4683 - val_loss: 1.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2761 - accuracy: 0.4524 - val_loss: 1.6706 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2690 - accuracy: 0.4841 - val_loss: 1.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2768 - accuracy: 0.4524 - val_loss: 1.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2687 - accuracy: 0.4921 - val_loss: 1.6741 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2692 - accuracy: 0.4841 - val_loss: 1.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2709 - accuracy: 0.4524 - val_loss: 1.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3059 - accuracy: 0.4127 - val_loss: 1.6724 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2867 - accuracy: 0.4286 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2777 - accuracy: 0.4444 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2744 - accuracy: 0.4365 - val_loss: 1.6708 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2674 - accuracy: 0.4841 - val_loss: 1.6744 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2706 - accuracy: 0.4683 - val_loss: 1.6686 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2695 - accuracy: 0.4524 - val_loss: 1.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2698 - accuracy: 0.4603 - val_loss: 1.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2663 - accuracy: 0.4921 - val_loss: 1.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2799 - accuracy: 0.4524 - val_loss: 1.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2770 - accuracy: 0.4365 - val_loss: 1.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2791 - accuracy: 0.4444 - val_loss: 1.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2744 - accuracy: 0.4524 - val_loss: 1.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2675 - accuracy: 0.4841 - val_loss: 1.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2782 - accuracy: 0.4603 - val_loss: 1.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2679 - accuracy: 0.4841 - val_loss: 1.6703 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2886 - accuracy: 0.4365 - val_loss: 1.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2723 - accuracy: 0.4683 - val_loss: 1.6725 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2657 - accuracy: 0.5079 - val_loss: 1.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2769 - accuracy: 0.4286 - val_loss: 1.6704 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2704 - accuracy: 0.4603 - val_loss: 1.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2645 - accuracy: 0.4921 - val_loss: 1.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2735 - accuracy: 0.4444 - val_loss: 1.6684 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3564 - accuracy: 0.3608\n",
      "Test loss: 1.3563510179519653\n",
      "Test accuracy: 0.3607594966888428\n"
     ]
    }
   ],
   "source": [
    "# mini batch\n",
    "\n",
    "model2.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model2.fit(X, Y, batch_size=64, epochs=50, validation_split=0.2)\n",
    "train_scores = model2.evaluate(X, Y, verbose=1)\n",
    "print(\"Test loss:\", train_scores[0])\n",
    "print(\"Test accuracy:\", train_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0beb3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 1.3045 - accuracy: 0.4048 - val_loss: 1.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2391 - accuracy: 0.5000 - val_loss: 1.6928 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2755 - accuracy: 0.4524 - val_loss: 1.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2409 - accuracy: 0.5000 - val_loss: 1.6982 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2442 - accuracy: 0.4841 - val_loss: 1.6968 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2517 - accuracy: 0.4603 - val_loss: 1.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2380 - accuracy: 0.5079 - val_loss: 1.7110 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2577 - accuracy: 0.4444 - val_loss: 1.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2548 - accuracy: 0.4762 - val_loss: 1.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2550 - accuracy: 0.4841 - val_loss: 1.6969 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.2436 - accuracy: 0.4841 - val_loss: 1.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2533 - accuracy: 0.4683 - val_loss: 1.6958 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2486 - accuracy: 0.4603 - val_loss: 1.6984 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2539 - accuracy: 0.4921 - val_loss: 1.7003 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2435 - accuracy: 0.5079 - val_loss: 1.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2519 - accuracy: 0.4762 - val_loss: 1.6961 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2472 - accuracy: 0.4683 - val_loss: 1.7110 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2631 - accuracy: 0.4603 - val_loss: 1.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2384 - accuracy: 0.4841 - val_loss: 1.7028 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2550 - accuracy: 0.4841 - val_loss: 1.6952 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2548 - accuracy: 0.4841 - val_loss: 1.6999 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2393 - accuracy: 0.5000 - val_loss: 1.7104 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.2417 - accuracy: 0.4841 - val_loss: 1.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2420 - accuracy: 0.4921 - val_loss: 1.7054 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2386 - accuracy: 0.4841 - val_loss: 1.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2382 - accuracy: 0.4921 - val_loss: 1.7034 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2393 - accuracy: 0.4841 - val_loss: 1.7029 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2635 - accuracy: 0.4603 - val_loss: 1.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2808 - accuracy: 0.4365 - val_loss: 1.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2440 - accuracy: 0.4841 - val_loss: 1.6961 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2567 - accuracy: 0.4683 - val_loss: 1.6981 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2744 - accuracy: 0.4365 - val_loss: 1.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2595 - accuracy: 0.4603 - val_loss: 1.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2427 - accuracy: 0.5000 - val_loss: 1.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2455 - accuracy: 0.4841 - val_loss: 1.7000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2781 - accuracy: 0.4603 - val_loss: 1.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2401 - accuracy: 0.4921 - val_loss: 1.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2396 - accuracy: 0.5000 - val_loss: 1.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2377 - accuracy: 0.5159 - val_loss: 1.7041 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2430 - accuracy: 0.4603 - val_loss: 1.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2413 - accuracy: 0.4841 - val_loss: 1.7001 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2459 - accuracy: 0.4762 - val_loss: 1.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2382 - accuracy: 0.4762 - val_loss: 1.7114 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2458 - accuracy: 0.4762 - val_loss: 1.6939 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2553 - accuracy: 0.4762 - val_loss: 1.7118 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2644 - accuracy: 0.4762 - val_loss: 1.7000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2499 - accuracy: 0.4921 - val_loss: 1.7049 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2422 - accuracy: 0.4921 - val_loss: 1.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2465 - accuracy: 0.4841 - val_loss: 1.7003 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2385 - accuracy: 0.4841 - val_loss: 1.7042 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3322 - accuracy: 0.3924\n",
      "Test loss: 1.3321921825408936\n",
      "Test accuracy: 0.39240506291389465\n"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "\n",
    "model2.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model2.fit(X, Y, batch_size=64, epochs=50, validation_split=0.2)\n",
    "train_scores = model2.evaluate(X, Y, verbose=1)\n",
    "print(\"Test loss:\", train_scores[0])\n",
    "print(\"Test accuracy:\", train_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13c9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
